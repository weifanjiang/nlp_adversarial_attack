{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demostrate Sentence-level Genetic Attack with Sentence Saliency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_level_genetic_attack import *\n",
    "import tensorflow as tf\n",
    "import stanfordnlp\n",
    "# uncomment if needed\n",
    "# stanfordnlp.download('en')\n",
    "nlp = stanfordnlp.Pipeline()\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # disable tensorflow loggings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model and dataset to attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build word_cnn model...\n",
      "successfully load model\n",
      "Processing IMDB dataset\n",
      "successfully load data\n"
     ]
    }
   ],
   "source": [
    "dataset = \"imdb\"\n",
    "model_name = \"pretrained_word_cnn\"\n",
    "\n",
    "model = word_cnn(dataset)\n",
    "model_path = r'./runs/{}/{}.dat'.format(dataset, model_name)\n",
    "model.load_weights(model_path)\n",
    "print(\"successfully load model\")\n",
    "\n",
    "# Data label for imdb dataset:\n",
    "# [1 0] is negative review\n",
    "# [0 1] is positive review\n",
    "\n",
    "train_texts, train_labels, test_texts, test_labels = split_imdb_files()\n",
    "x_train, y_train, x_test, y_test = word_process(train_texts, train_labels, test_texts, test_labels, dataset)\n",
    "print('successfully load data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demostration\n",
    "\n",
    "Used test sample 12654 for demostration purposes.\n",
    "\n",
    "In general, test samples which model does not produce very certain predictions are more likely to have successful attack result. In this case, model predict sample 12654 to be negative with probability = 0.69. Our attack is harder to success if this probability is very high (i.e. >= 0.95).\n",
    "\n",
    "Other samples that are easy to success: 12654, 902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean sample: This film probably would have been good,if they didn't use CGI (computer generated imagery)for the werewolf scenes.It made the creatures look fake and the werewolves looked cartoonish.CGI is great for certain effects like the dinasours in Jurassic Park or Twister.But when we see a film where the creature must look completely real,CGI is not the way to go.Look at An American Werewolf in London.No CGI.Just makeup and a mechanical creature and what you come up with was more realistic than what was shown in the sequel.This film did offer a few gags that was fun to watch and the humor in this movie seemed to have drawn me in but it's nothing more than a film that I thought was O.K.And that's not good enough.In my opinion,An American Werewolf in Paris doesn't hold up to the original.\n",
      "Actual label: [1, 0]\n",
      "Model Prediction: [0.68962145 0.30292207]\n"
     ]
    }
   ],
   "source": [
    "test_idx = 12654\n",
    "xi_text = test_texts[test_idx]\n",
    "yi = test_labels[test_idx]\n",
    "print(\"Clean sample: {}\".format(xi_text))\n",
    "print(\"Actual label: {}\".format(yi))\n",
    "print(\"Model Prediction: {}\".format(predict_str(model, xi_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demo computing sentence salience\n",
    "\n",
    "Let $x = s_1s_2\\dots s_n$ be a input consists of $n$ sentences. Let $y$ be $x$'s true label. The sentence saliency for sentence $s_k$ is:\n",
    "\n",
    "$$S(y|s_k) = P(y|x) - P(x|s_1s_2\\dots s_{k-1}s_{k+1}\\dots s_n)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/TensorAdvancedIndexing.cpp:543: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw sentence saliency: [ 0.09119469 -0.0176931  -0.2083224  -0.03500342  0.00458783  0.02031082\n",
      " -0.01235932  0.05155784  0.00589448  0.00220156]\n",
      "Softmax sentence saliency: [0.22486347 0.07568769 0.01124949 0.06365719 0.094578   0.11068129\n",
      " 0.0798343  0.15127885 0.0958219  0.09234782]\n"
     ]
    }
   ],
   "source": [
    "# break input string to list of sentences\n",
    "doc = nlp(xi_text)\n",
    "sentences = sentence_list(doc)\n",
    "\n",
    "# Compute saliency scores\n",
    "raw_saliency = sentence_saliency(model, sentences, yi)\n",
    "\n",
    "# Compute normalized saliency scores with softmax\n",
    "saliency_scores = softmax(raw_saliency, 10)\n",
    "\n",
    "print(\"Raw sentence saliency: {}\".format(raw_saliency))\n",
    "print(\"Softmax sentence saliency: {}\".format(saliency_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demo back-translation for sentence rephrasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean sentence: I love to play with little furry cats.\n",
      "Pivot translation to Chinese: 我喜欢和毛茸茸的小猫一起玩。\n",
      "Final back translation result: I like to play with furry kittens.\n"
     ]
    }
   ],
   "source": [
    "clean_sentence = \"I love to play with little furry cats.\"\n",
    "pivot, final = back_translation(clean_sentence, language = 'zh', require_mid = True)\n",
    "print(\"Clean sentence: {}\".format(clean_sentence))\n",
    "print(\"Pivot translation to Chinese: {}\".format(pivot))\n",
    "print(\"Final back translation result: {}\".format(final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demo genetic attack with verbose output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/TensorAdvancedIndexing.cpp:543: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean sample's prediction: [0.68962145 0.30292207]\n",
      "target is to make index 1 > 0.5\n",
      "generation 1\n",
      "population 0 pred: [0.6338001  0.36262536]\n",
      "population 1 pred: [0.7572598  0.24051255]\n",
      "population 2 pred: [0.67821705 0.31816134]\n",
      "population 3 pred: [0.6730638  0.32398772]\n",
      "population 4 pred: [0.65763974 0.33833525]\n",
      "population 5 pred: [0.70253444 0.29128775]\n",
      "population 6 pred: [0.7130803  0.28080446]\n",
      "population 7 pred: [0.46511325 0.5361443 ]\n",
      "successful adv. example found!\n",
      "adv example: This film probably would have been good, if they did n't use CGI( computer generated imagery) for the werewolf scenes. It made the creatures look fake and the werewolves looked cartoonish. CGI is great for certain effects like the dinasours in Jurassic Park or Twister. But when we see a film where the creature must look completely real, CGI is not the way to go. Look at An American Werewolf in London. No CGI. Just makeup and a mechanical creature and what you come up with was more realistic than what was shown in the sequel. This movie had a bit of gags that was fun to watch and the humor of this movie attracted me but it’s nothing more than a movie that I thought was good. And that's not good enough. In my opinion, An American Werewolf in Paris does n't hold up to the original.\n",
      "clean sample: [0.68962145 0.30292207]\n",
      "adv example pred: [0.46511325 0.5361443 ]\n"
     ]
    }
   ],
   "source": [
    "adv_example = genetic(xi_text, yi, model, 10, 5, load_cache(), verbose = True)\n",
    "print(\"adv example: {}\".format(adv_example))\n",
    "print(\"clean sample: {}\".format(predict_str(model, xi_text)))\n",
    "print(\"adv example pred: {}\".format(predict_str(model, adv_example)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
