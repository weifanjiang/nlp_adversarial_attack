# NLP Adversarial Attack

Course Project for [COMS 6998-10: Robustness and Security in ML Systems](http://www.cs.columbia.edu/~junfeng/20sp-e6998/), Spring 2020 at Columbia University.

Group members:
- Weifan Jiang (wj2301)
- Haoxuan Wu (hw2754)

## Goal

We try to generate adversarial examples for NLP models with black-box access (only predictions and confidence in prediction is accessible). We aim to produce adversarial example with sentence-level perturbation.
